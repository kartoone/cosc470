{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kartoone/cosc470/blob/main/examples/llm/tf-keras-embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKO8U8yiUE-R"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "o9nhCU2UUE-R"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras import layers\n",
        "from keras import ops"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uk7CxZ6ZUE-U"
      },
      "source": [
        "You can also create a Sequential model incrementally via the `add()` method:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "4x8LqztRUE-W",
        "outputId": "0f8e488f-4934-4507-df2c-b2dbe460c243"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                   │              \u001b[38;5;34m10\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   │              \u001b[38;5;34m12\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m22\u001b[0m (88.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22</span> (88.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m22\u001b[0m (88.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22</span> (88.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "model = keras.Sequential()\n",
        "model.add(keras.Input(shape=(4,)))  # 4 words in our vocab\n",
        "model.add(layers.Dense(2, activation=\"linear\")) # two numbers to represent each word\n",
        "model.add(layers.Dense(4, activation=\"softmax\")) # 4 words in our vocab\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krX6-RfMUE-W"
      },
      "source": [
        "Note that the `Input` object is not displayed as part of `model.layers`, since\n",
        "it isn't a layer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0cJu4nsUE-W",
        "outputId": "1aa0274c-93af-4dc1-e8bc-4469497664d4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<Dense name=dense, built=True>, <Dense name=dense_1, built=True>]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "model.layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "g_LbsE_pUE-X",
        "outputId": "4651d5a3-05bc-4832-b8b1-b2c3e79e1ba7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/models/functional.py:237: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
            "Expected: ['keras_tensor']\n",
            "Received: inputs=Tensor(shape=(20, 4))\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "weight_embedding_model = keras.Model(\n",
        "    inputs=model.inputs,\n",
        "    outputs=[layer.output for layer in model.layers],\n",
        ")\n",
        "\n",
        "# Call feature extractor on test input.\n",
        "x = ops.ones((20, 4, ))\n",
        "features = weight_embedding_model(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5RhOTQsUE-X"
      },
      "source": [
        "Here's a similar example that only extract features from one layer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YUTnBuNGUE-X"
      },
      "outputs": [],
      "source": [
        "initial_model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(250, 250, 3)),\n",
        "        layers.Conv2D(32, 5, strides=2, activation=\"relu\"),\n",
        "        layers.Conv2D(32, 3, activation=\"relu\", name=\"my_intermediate_layer\"),\n",
        "        layers.Conv2D(32, 3, activation=\"relu\"),\n",
        "    ]\n",
        ")\n",
        "feature_extractor = keras.Model(\n",
        "    inputs=initial_model.inputs,\n",
        "    outputs=initial_model.get_layer(name=\"my_intermediate_layer\").output,\n",
        ")\n",
        "# Call feature extractor on test input.\n",
        "x = ops.ones((1, 250, 250, 3))\n",
        "features = feature_extractor(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQdo3Et4UE-f"
      },
      "source": [
        "## Transfer learning with a Sequential model\n",
        "\n",
        "Transfer learning consists of freezing the bottom layers in a model and only training\n",
        "the top layers. If you aren't familiar with it, make sure to read our [guide\n",
        "to transfer learning](/guides/transfer_learning/).\n",
        "\n",
        "Here are two common transfer learning blueprint involving Sequential models.\n",
        "\n",
        "First, let's say that you have a Sequential model, and you want to freeze all\n",
        "layers except the last one. In this case, you would simply iterate over\n",
        "`model.layers` and set `layer.trainable = False` on each layer, except the\n",
        "last one. Like this:\n",
        "\n",
        "```python\n",
        "model = keras.Sequential([\n",
        "    keras.Input(shape=(784)),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(10),\n",
        "])\n",
        "\n",
        "# Presumably you would want to first load pre-trained weights.\n",
        "model.load_weights(...)\n",
        "\n",
        "# Freeze all layers except the last one.\n",
        "for layer in model.layers[:-1]:\n",
        "  layer.trainable = False\n",
        "\n",
        "# Recompile and train (this will only update the weights of the last layer).\n",
        "model.compile(...)\n",
        "model.fit(...)\n",
        "```\n",
        "\n",
        "Another common blueprint is to use a Sequential model to stack a pre-trained\n",
        "model and some freshly initialized classification layers. Like this:\n",
        "\n",
        "```python\n",
        "# Load a convolutional base with pre-trained weights\n",
        "base_model = keras.applications.Xception(\n",
        "    weights='imagenet',\n",
        "    include_top=False,\n",
        "    pooling='avg')\n",
        "\n",
        "# Freeze the base model\n",
        "base_model.trainable = False\n",
        "\n",
        "# Use a Sequential model to add a trainable classifier on top\n",
        "model = keras.Sequential([\n",
        "    base_model,\n",
        "    layers.Dense(1000),\n",
        "])\n",
        "\n",
        "# Compile & train\n",
        "model.compile(...)\n",
        "model.fit(...)\n",
        "```\n",
        "\n",
        "If you do transfer learning, you will probably find yourself frequently using\n",
        "these two patterns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--YuGG7iUE-f"
      },
      "source": [
        "That's about all you need to know about Sequential models!\n",
        "\n",
        "To find out more about building models in Keras, see:\n",
        "\n",
        "- [Guide to the Functional API](/guides/functional_api/)\n",
        "- [Guide to making new Layers & Models via subclassing](/guides/making_new_layers_and_models_via_subclassing/)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "sequential_model",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}